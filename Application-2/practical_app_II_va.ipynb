{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv('data/vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = vehicles.convert_dtypes()\n",
    "original_row_count = vehicles.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALC: % of null values\n",
    "vehicles.isnull().sum()/vehicles.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a few features (columns) that are not relavent to the analysis\n",
    "vehicles.drop(columns = ['id','region','VIN','state'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before dropping NaN's\n",
    "px.imshow(vehicles.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.select_dtypes(['Int64','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=['price', 'year', 'odometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.select_dtypes(['string']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols=['manufacturer', 'model', 'condition', 'cylinders', 'fuel',\n",
    "       'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup & Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_NaN_df(df, cols):\n",
    "    for col in cols:\n",
    "        df = df[df[col].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing NaN's from columns that dont carry a significant amount of NaN's or hold values are might skew analysis if \n",
    "# improperly guessed, hence will remove those entires ( after careful analysis of the quantity ) to prevent prediction\n",
    "# errors - e.g. fuel or title_status\n",
    "cols = ['year','odometer','manufacturer','model','fuel','title_status']\n",
    "vehicles = remove_NaN_df(vehicles, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations to understand current outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles, x='price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles, x='year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles, x='odometer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df = vehicles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundaries(df, variable, distance):\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR*distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR*distance)\n",
    "    \n",
    "    return lower_boundary, upper_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(vehicles_df, 'price', 1.5)\n",
    "outliers_p = np.where(vehicles_df['price'] > up, True, \n",
    "                    np.where(vehicles_df['price'] < lo, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df=vehicles_df.loc[~outliers_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(vehicles_df, 'odometer', 1.5)\n",
    "outliers_o = np.where(vehicles_df['odometer'] > up, True, \n",
    "                    np.where(vehicles_df['odometer'] < lo, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df=vehicles_df.loc[~outliers_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(vehicles_df, 'odometer', 1.5)\n",
    "outliers_y = np.where(vehicles_df['year'] > up, True, \n",
    "                    np.where(vehicles_df['year'] < lo, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df=vehicles_df.loc[~outliers_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'parts only' from the title_status because this category offers no real value  - (NOMIAL datatype)\n",
    "title_status_values = ['parts only']\n",
    "vehicles_df = vehicles_df[vehicles_df.title_status.isin(title_status_values) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations after adjusting outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles_df, x='price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles_df, x='year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles_df, x='odometer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much % of data removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('% of data removed ===>',((original_row_count-vehicles_df.shape[0])/(original_row_count))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many NaN's are in each categorical feature\n",
    "dummy_df = vehicles_df[obj_cols].copy()\n",
    "dummy_df.isna().sum().reset_index(name=\"n\").plot.bar(x='index', y='n', rot=45)\n",
    "\n",
    "print(dummy_df.isna().sum().reset_index(name=\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all NaN's are removed, what's left need to be imputed.\n",
    "px.imshow(vehicles_df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use encoder to encode categorical features.\n",
    "cols_to_enc = ['manufacturer','model','condition','cylinders','fuel','title_status','transmission','drive','size','type','paint_color']\n",
    "X = vehicles_df.drop(columns=['price'], axis=1)\n",
    "y = vehicles_df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "encoder = ce.JamesSteinEncoder(cols=cols_to_enc)\n",
    "X_train_enc = encoder.fit_transform(X_train, y_train)\n",
    "X_test_enc = encoder.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final EDA on the cleaned data for insights - before moving on to modelling\n",
    "vehicles[obj_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Simple Linear Regression - with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_features_linreg = ''\n",
    "linreg_mse = ''\n",
    "\n",
    "# keeping the intercept term to false\n",
    "linreg_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                        ('lreg', LinearRegression())]).fit(X_train_enc, y_train)\n",
    "train_preds = linreg_pipe.predict(X_train_enc)\n",
    "test_preds = linreg_pipe.predict(X_test_enc)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Linear Regression Train MSE: {np.around(train_mse,2)}')\n",
    "print(f'Linear Regression Test MSE: {np.around(test_mse,2)}')\n",
    "\n",
    "lr_coef = linreg_pipe.named_steps['lreg'].coef_\n",
    "lr_intercept = linreg_pipe.named_steps['lreg'].intercept_\n",
    "print(f'Intercept: {np.around(lr_intercept,2)}')\n",
    "\n",
    "list_lr_coef = list((zip(linreg_pipe.named_steps['scaler'].get_feature_names_out(), linreg_pipe.named_steps['lreg'].coef_)))\n",
    "lr_coef_df = pd.DataFrame(list_lr_coef, columns = [' Features', 'Coefficients'])\n",
    "lr_coef_df.sort_values(by='Coefficients', ascending=False, key=abs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-Simple Linear Regression</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>fit_intercept is false: </b>\n",
    "1. Train MSE: 351884283.44\n",
    "2. Test MSE: 353533750.09\n",
    "3. Intercept: 0.0\n",
    "\n",
    "<b>fit_intercept is True: </b>\n",
    "1. Train MSE: 66852359.27\n",
    "2. Test MSE: 71854716.44\n",
    "3. Intercept: 16882.89\n",
    "\n",
    "\n",
    "<b>Theory:</b> <i>A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease<i>\n",
    "\n",
    "At this stage we can draw a quick inference by looking at the coefficients that ones that have a negative affect on the price are <span style=\"color:red\"> odometer, transmission & condition</span>. The more the odometer, the cheaper is the car & so goes with the condition ( old is less expensive ). Model has the most impact on the price followed by the year of the car. Newer makes are more expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\n",
    "param_dict = {'ridge__alpha': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_grid = ''\n",
    "ridge_train_mse = ''\n",
    "ridge_test_mse = ''\n",
    "ridge_best_alpha = ''\n",
    "\n",
    "r_grid = GridSearchCV(ridge_pipe, param_grid=param_dict).fit(X_train_enc, y_train)\n",
    "\n",
    "train_preds = r_grid.predict(X_train_enc)\n",
    "test_preds = r_grid.predict(X_test_enc)\n",
    "\n",
    "ridge_train_mse = mean_squared_error(y_train, train_preds)\n",
    "ridge_test_mse = mean_squared_error(y_test, test_preds)\n",
    "ridge_best_alpha = r_grid.best_params_\n",
    "\n",
    "print(f'Ridge Regression Train MSE: {np.around(ridge_train_mse,2)}')\n",
    "print(f'Ridge Regression Test MSE: {np.around(ridge_test_mse,2)}')\n",
    "print(f'Best Alpha: {list(ridge_best_alpha.values())[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-Ridge Regression</span>\n",
    "\n",
    "1. Ridge Regression Train MSE: 66852359.42\n",
    "2. Ridge Regression Test MSE: 71854450.24\n",
    "3. Best Alpha: 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_coef_list = []\n",
    "\n",
    "# for best alpha = 10 find out all the coeffs ( captured in the ridge_best_alpha variable above)\n",
    "ridge_pipe_4best_alpha = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge(alpha=10))])\n",
    "ridge_pipe_4best_alpha.fit(X_train_enc, y_train)\n",
    "\n",
    "ridge_coef_list.append(list(ridge_pipe_4best_alpha.named_steps['ridge'].coef_))\n",
    "len(ridge_coef_list)\n",
    "print('For alpha = 10 we have the following coefficients:')\n",
    "list(zip(X_train_enc.columns, ridge_coef_list[-1]))\n",
    "\n",
    "ridge_coef_df = pd.DataFrame(list(zip(X_train_enc.columns, ridge_coef_list[-1])), columns = [' Features', 'Coefficients'])\n",
    "ridge_coef_df.sort_values(by='Coefficients', ascending=False, key=abs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, with the best alpha (10), Ridge Regression gives us almost similar results as a simple linear regression. We can draw a quick inference by looking at the coefficients that ones that have a negative affect on the price are <span style=\"color:red\"> odometer, transmission & condition</span>, similar to LR model above. Model & Year have positive affect on the price of the used car vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lasso_grid = ''\n",
    "lasso_train_mse = ''\n",
    "lasso_test_mse = ''\n",
    "lasso_coefs = ''\n",
    "\n",
    "lasso_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                       ('lasso', Lasso(random_state = 42))]).fit(X_train_enc, y_train)\n",
    "\n",
    "\n",
    "train_preds = lasso_pipe.predict(X_train_enc)\n",
    "test_preds = lasso_pipe.predict(X_test_enc)\n",
    "\n",
    "lasso_train_mse = mean_squared_error(y_train, train_preds)\n",
    "lasso_test_mse = mean_squared_error(y_test, test_preds)\n",
    "lasso_coefs = lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "feature_names = X_train_enc.columns\n",
    "lasso_df = pd.DataFrame({'feature': feature_names, 'Coefficients': lasso_coefs})\n",
    "\n",
    "print(f'LASSO Train MSE: {np.around(lasso_train_mse,2)}')\n",
    "print(f'LASSO Test MSE: {np.around(lasso_test_mse,2)}')\n",
    "\n",
    "lasso_df.sort_values(by='Coefficients', ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-LASSO</span>\n",
    "\n",
    "1. LASSO Train MSE: 69658578.85\n",
    "2. LASSO Test MSE: 75505613.41\n",
    "\n",
    "LASSO Regression gives us the same results as the previous 2 regression models with respect to the behvior of the best features with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SFS - To identify a list of features that have the most influence on the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_lr_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                        ('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                        ('lr_model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_dict = {}\n",
    "sfs_lr_grid = ''\n",
    "sfs_lr_train_mse = ''\n",
    "sfs_lr_test_mse = ''\n",
    "\n",
    "param_dict = {'selector__n_features_to_select': [4, 5, 6]}\n",
    "sfs_lr_grid = GridSearchCV(sfs_lr_pipe, param_grid=param_dict).fit(X_train_enc, y_train)\n",
    "\n",
    "train_preds = sfs_lr_grid.predict(X_train_enc)\n",
    "test_preds = sfs_lr_grid.predict(X_test_enc)\n",
    "\n",
    "sfs_lr_train_mse = mean_squared_error(y_train, train_preds)\n",
    "sfs_lr_test_mse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Minimum Train MSE is : {np.around(sfs_lr_train_mse,2)}')\n",
    "print(f'Minimum Test MSE is: {np.around(sfs_lr_test_mse,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = ''\n",
    "best_selector = ''\n",
    "best_model = ''\n",
    "feature_names = ''\n",
    "coefs = ''\n",
    "\n",
    "best_estimator = sfs_lr_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = sfs_lr_grid.best_estimator_.named_steps['lr_model']\n",
    "feature_names = X_train_enc.columns[best_selector.get_support()]\n",
    "coefs = best_model.coef_\n",
    "\n",
    "print(best_estimator)\n",
    "print(f'Features from best selector: {feature_names}.')\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "pd.DataFrame([coefs.T], columns = feature_names, index = ['lr_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare encoded data down to the list of top 6 features identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = ['year','model','odometer','transmission','drive','type']\n",
    "\n",
    "X_top_train_enc = X_train_enc[top_features]\n",
    "X_top_test_enc = X_test_enc[top_features]\n",
    "\n",
    "X_top_train_enc.shape, X_top_test_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Degree & Linear Regression --- To identify the best degree for the features identified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "polyd_lr_train_mses = []\n",
    "polyd_lr_test_mses = []\n",
    "\n",
    "best_polyd = ''\n",
    "\n",
    "for i in range(1, 3):\n",
    "    pipe = Pipeline([('pfeat', PolynomialFeatures(degree = i, include_bias=False)),\n",
    "                     ('scale', StandardScaler()),\n",
    "                     ('linreg', LinearRegression())]).fit(X_top_train_enc, y_train)\n",
    "    \n",
    "    train_preds = pipe.predict(X_top_train_enc)\n",
    "    test_preds = pipe.predict(X_top_test_enc)\n",
    "    polyd_lr_train_mses.append(mean_squared_error(y_train, train_preds))\n",
    "    polyd_lr_test_mses.append(mean_squared_error(y_test, test_preds))\n",
    "    \n",
    "best_polyd_test = polyd_lr_test_mses.index(min(polyd_lr_test_mses)) + 1\n",
    "\n",
    "print(f'Train MSE is: {np.around(polyd_lr_train_mses,2)}')\n",
    "print(f'Test MSE is: {np.around(polyd_lr_test_mses,2)}')\n",
    "best_polyd_train = polyd_lr_train_mses.index(min(polyd_lr_train_mses)) + 1\n",
    "best_polyd_test = polyd_lr_test_mses.index(min(polyd_lr_test_mses)) + 1\n",
    "\n",
    "print(f'Best TRAIN performing degree model : {best_polyd_train}')\n",
    "print(f'Best TEST performing degree model : {best_polyd_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial with Degree = 2 ( best degree ) & Ridge Regression ( to identify best alpha ... will it change? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pd_ridge_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 2, include_bias= False)),\n",
    "                          ('scaler', StandardScaler()), \n",
    "                          ('ridge', Ridge())])\n",
    "param_dict = {'ridge__alpha': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "pd_ridge_grid = ''\n",
    "pd_ridge_train_mse = ''\n",
    "pd_ridge_test_mse = ''\n",
    "pd_ridge_best_alpha = ''\n",
    "\n",
    "pd_ridge_grid = GridSearchCV(pd_ridge_pipe, param_grid=param_dict).fit(X_top_train_enc, y_train)\n",
    "\n",
    "train_preds = pd_ridge_grid.predict(X_top_train_enc)\n",
    "test_preds = pd_ridge_grid.predict(X_top_test_enc)\n",
    "\n",
    "pd_ridge_train_mse = mean_squared_error(y_train, train_preds)\n",
    "pd_ridge_test_mse = mean_squared_error(y_test, test_preds)\n",
    "pd_ridge_best_alpha = pd_ridge_grid.best_params_\n",
    "\n",
    "print(f'Polynomial with Degree =2 & Ridge Regression Train MSE: {np.around(pd_ridge_train_mse,2)}')\n",
    "print(f'Polynomial with Degree =2 & Ridge Regression Test MSE: {np.around(pd_ridge_test_mse,2)}')\n",
    "print(f'Best Alpha: {list(pd_ridge_best_alpha.values())[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO Regression with  Degree = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lasso_pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('lasso', Lasso(random_state = 42))]).fit(X_top_train_enc, y_train)\n",
    "\n",
    "train_preds = pd_lasso_pipe.predict(X_top_train_enc)\n",
    "test_preds = pd_lasso_pipe.predict(X_top_test_enc)\n",
    "\n",
    "lasso_train_mse = mean_squared_error(y_train, train_preds)\n",
    "lasso_test_mse = mean_squared_error(y_test, test_preds)\n",
    "lasso_coefs = pd_lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "pd_lasso_coefs = pd_lasso_pipe.named_steps['lasso'].coef_\n",
    "feature_names = X_train_enc.columns\n",
    "\n",
    "print(f'LASSO Train MSE: {np.around(lasso_train_mse,2)}')\n",
    "print(f'LASSO Test MSE: {np.around(lasso_test_mse,2)}')\n",
    "\n",
    "list_lasso_coeff = list((zip(pd_lasso_pipe.named_steps['polyfeatures'].get_feature_names_out(), \n",
    "                             pd_lasso_pipe.named_steps['lasso'].coef_)))\n",
    "pd_lasso_df = pd.DataFrame(list_lasso_coeff, columns = [' Features', 'Lasso Coefficients'])\n",
    "pd_lasso_df.sort_values(by='Lasso Coefficients', ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd_lasso_pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "coefs = pd_lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "print(best_estimator)\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "errors = pd.DataFrame([coefs.T], columns = feature_names, index = ['lr_model'])\n",
    "errors[errors.columns[(abs(errors) > 0.000001).any()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best fitting model - (Linear Regression degree 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "pipe = Pipeline([('pfeat', PolynomialFeatures(degree = 2, include_bias=False)),\n",
    "                     ('scale', StandardScaler()),\n",
    "                     ('linreg', LinearRegression())]).fit(X_top_train_enc, y_train)\n",
    "train_preds = pipe.predict(X_top_train_enc)\n",
    "test_preds = pipe.predict(X_top_test_enc)\n",
    "\n",
    "metrics.mean_squared_error(y_test, test_preds, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Feature Importance with best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(pipe, X_top_test_enc, y_test,\n",
    "                           random_state=123)\n",
    "pd.DataFrame({\"Variables\":X_top_test_enc.columns,\"Score\":r.importances_mean}).sort_values(by=\"Score\",ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations on the top selected features {model, year, odometer, drive, transmission, type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cols=['model','manufacturer','drive','transmission','type']\n",
    "vehicles_df[top_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for top 3 models among each manufacturer\n",
    "N = 3\n",
    "msk = vehicles_df.groupby('manufacturer')['price'].rank(method='first', ascending=False) <= N\n",
    "models_df = vehicles_df[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(models_df,x='model',y='price',color='manufacturer',width=1200,height=1000)\n",
    "fig.show(\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inventory layout\n",
    "sns.countplot(data = vehicles_df, x = \"manufacturer\")\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transmission\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(x = vehicles_df['transmission'], y = vehicles_df['price'], palette = 'husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "plt.figure(figsize=(40,10))\n",
    "sns.boxplot(x = vehicles_df['type'], y = vehicles_df['price'], palette = 'husl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
