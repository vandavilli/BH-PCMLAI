{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv('data/vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = vehicles.convert_dtypes()\n",
    "vehicles.info()\n",
    "original_row_count = vehicles.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALC: % of null values\n",
    "vehicles.isnull().sum()/vehicles.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a few features (columns) that are not relavent to the analysis\n",
    "vehicles.drop(columns = ['id','region','VIN','state'], axis=1, inplace = True)\n",
    "vehicles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before dropping NaN's\n",
    "px.imshow(vehicles.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.select_dtypes(['Int64','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=['price', 'year', 'odometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.select_dtypes(['string']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols=['manufacturer', 'model', 'condition', 'cylinders', 'fuel',\n",
    "       'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup & Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_NaN_df(df, cols):\n",
    "    for col in cols:\n",
    "        df = df[df[col].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing NaN's from columns that dont carry a significant amount of NaN's or hold values are might skew analysis if \n",
    "# improperly guessed, hence will remove those entires ( after careful analysis of the quantity ) to prevent prediction\n",
    "# errors - e.g. fuel or title_status\n",
    "cols = ['year','odometer','manufacturer','model','fuel','title_status']\n",
    "vehicles = remove_NaN_df(vehicles, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles, x='price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles, x='year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles, x='odometer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df = vehicles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundaries(df, variable, distance):\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR*distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR*distance)\n",
    "    \n",
    "    return lower_boundary, upper_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(vehicles_df, 'price', 1.5)\n",
    "outliers_p = np.where(vehicles_df['price'] > up, True, \n",
    "                    np.where(vehicles_df['price'] < lo, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df=vehicles_df.loc[~outliers_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(vehicles_df, 'odometer', 1.5)\n",
    "outliers_o = np.where(vehicles_df['odometer'] > up, True, \n",
    "                    np.where(vehicles_df['odometer'] < lo, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df=vehicles_df.loc[~outliers_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, up = find_boundaries(vehicles_df, 'odometer', 1.5)\n",
    "outliers_y = np.where(vehicles_df['year'] > up, True, \n",
    "                    np.where(vehicles_df['year'] < lo, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df=vehicles_df.loc[~outliers_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('% of data removed ===>',((original_row_count-vehicles_df.shape[0])/(original_row_count))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'parts only' from the title_status because this category offers no real value  - (NOMIAL datatype)\n",
    "title_status_values = ['parts only']\n",
    "vehicles_df = vehicles_df[vehicles_df.title_status.isin(title_status_values) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some sanity checks !!!\n",
    "vehicles_df[vehicles_df['year']==1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles_df, x='price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles_df, x='year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data=vehicles_df, x='odometer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for some interesting price to feature depencies {model, year, odometer, transmission, size, paint_color, type }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of the categorical features in the dataset\n",
    "vehicles_df[obj_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-Summary Statistics</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grouped boxplot - which drive is more pricy?\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(x = vehicles_df['drive'], y = vehicles_df['price'], palette = 'husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-price vs year & manufacturer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.scatter(vehicles_df, x='year', y='price', color='manufacturer')\n",
    "fig1.show(\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-price vs odometer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which manufacturer is more popular among used car buyers?\n",
    "plt.figure(figsize=(40,10))\n",
    "sns.boxplot(x = vehicles_df['manufacturer'], y = vehicles_df['price'], palette = 'husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-price vs transmission</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which model is more expensive\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(x = vehicles_df['transmission'], y = vehicles_df['price'], palette = 'husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-price vs size</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which size sells the most & how expensive is it\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(x = vehicles_df['size'], y = vehicles_df['price'], palette = 'husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-price vs paint_color</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which color is more expensive\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(x = vehicles_df['paint_color'], y = vehicles_df['price'], palette = 'husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-price vs type</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many NaN's are in each categorical feature\n",
    "dummy_df = vehicles_df[obj_cols].copy()\n",
    "dummy_df.isna().sum().reset_index(name=\"n\").plot.bar(x='index', y='n', rot=45)\n",
    "\n",
    "print(dummy_df.isna().sum().reset_index(name=\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(vehicles_df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use encoder to encode categorical features.\n",
    "cols_to_enc = ['manufacturer','model','condition','cylinders','fuel','title_status','transmission','drive','size','type','paint_color']\n",
    "X = vehicles_df.drop(columns=['price'], axis=1)\n",
    "y = vehicles_df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "encoder = ce.JamesSteinEncoder(cols=cols_to_enc)\n",
    "X_train_enc = encoder.fit_transform(X_train, y_train)\n",
    "X_test_enc = encoder.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Linear Regression - with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_features_linreg = ''\n",
    "linreg_mse = ''\n",
    "\n",
    "# keeping the intercept term to false\n",
    "linreg_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                        ('lreg', LinearRegression())]).fit(X_train_enc, y_train)\n",
    "train_preds = linreg_pipe.predict(X_train_enc)\n",
    "test_preds = linreg_pipe.predict(X_test_enc)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Linear Regression Train MSE: {np.around(train_mse,2)}')\n",
    "print(f'Linear Regression Test MSE: {np.around(test_mse,2)}')\n",
    "\n",
    "lr_coef = linreg_pipe.named_steps['lreg'].coef_\n",
    "lr_intercept = linreg_pipe.named_steps['lreg'].intercept_\n",
    "print(f'Intercept: {np.around(lr_intercept,2)}')\n",
    "\n",
    "list_lr_coef = list((zip(linreg_pipe.named_steps['scaler'].get_feature_names_out(), linreg_pipe.named_steps['lreg'].coef_)))\n",
    "lr_coef_df = pd.DataFrame(list_lr_coef, columns = [' Features', 'Coefficients'])\n",
    "lr_coef_df.sort_values(by='Coefficients', ascending=False, key=abs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-Simple Linear Regression</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>fit_intercept is false: </b>\n",
    "1. Train MSE: 351884283.44\n",
    "2. Test MSE: 353533750.09\n",
    "3. Intercept: 0.0\n",
    "\n",
    "<b>fit_intercept is True: </b>\n",
    "1. Train MSE: 66852359.27\n",
    "2. Test MSE: 71854716.44\n",
    "3. Intercept: 16882.89\n",
    "\n",
    "\n",
    "<b>Theory:</b> <i>A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease<i>\n",
    "\n",
    "At this stage we can draw a quick inference by looking at the coefficients that ones that have a negative affect on the price are <span style=\"color:red\"> odometer, transmission & condition</span>. The more the odometer, the cheaper is the car & so goes with the condition ( old is less expensive ). Model has the most impact on the price followed by the year of the car. Newer makes are more expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\n",
    "param_dict = {'ridge__alpha': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r_grid = ''\n",
    "ridge_train_mse = ''\n",
    "ridge_test_mse = ''\n",
    "ridge_best_alpha = ''\n",
    "\n",
    "r_grid = GridSearchCV(ridge_pipe, param_grid=param_dict).fit(X_train_enc, y_train)\n",
    "\n",
    "train_preds = r_grid.predict(X_train_enc)\n",
    "test_preds = r_grid.predict(X_test_enc)\n",
    "\n",
    "ridge_train_mse = mean_squared_error(y_train, train_preds)\n",
    "ridge_test_mse = mean_squared_error(y_test, test_preds)\n",
    "ridge_best_alpha = r_grid.best_params_\n",
    "\n",
    "print(f'Ridge Regression Train MSE: {np.around(ridge_train_mse,2)}')\n",
    "print(f'Ridge Regression Test MSE: {np.around(ridge_test_mse,2)}')\n",
    "print(f'Best Alpha: {list(ridge_best_alpha.values())[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-Ridge Regression</span>\n",
    "\n",
    "1. Ridge Regression Train MSE: 66852359.42\n",
    "2. Ridge Regression Test MSE: 71854450.24\n",
    "3. Best Alpha: 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_coef_list = []\n",
    "\n",
    "# for best alpha = 10 find out all the coeffs ( captured in the ridge_best_alpha variable above)\n",
    "ridge_pipe_4best_alpha = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge(alpha=10))])\n",
    "ridge_pipe_4best_alpha.fit(X_train_enc, y_train)\n",
    "\n",
    "ridge_coef_list.append(list(ridge_pipe_4best_alpha.named_steps['ridge'].coef_))\n",
    "len(ridge_coef_list)\n",
    "print('For alpha = 10 we have the following coefficients:')\n",
    "list(zip(X_train_enc.columns, ridge_coef_list[-1]))\n",
    "\n",
    "ridge_coef_df = pd.DataFrame(list(zip(X_train_enc.columns, ridge_coef_list[-1])), columns = [' Features', 'Coefficients'])\n",
    "ridge_coef_df.sort_values(by='Coefficients', ascending=False, key=abs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, with the best alpha (10), Ridge Regression gives us almost similar results as a simple linear regression. We can draw a quick inference by looking at the coefficients that ones that have a negative affect on the price are <span style=\"color:red\"> odometer, transmission & condition</span>, similar to LR model above. Model & Year have positive affect on the price of the used car vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE TO SELF .. make sure you are predicting again with the new pipe\n",
    "\n",
    "%%time\n",
    "lasso_grid = ''\n",
    "lasso_train_mse = ''\n",
    "lasso_test_mse = ''\n",
    "lasso_coefs = ''\n",
    "\n",
    "lasso_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                       ('lasso', Lasso(random_state = 42))]).fit(X_train_enc, y_train)\n",
    "\n",
    "\n",
    "train_preds = lasso_pipe.predict(X_train_enc)\n",
    "test_preds = lasso_pipe.predict(X_test_enc)\n",
    "\n",
    "lasso_train_mse = mean_squared_error(y_train, train_preds)\n",
    "lasso_test_mse = mean_squared_error(y_test, test_preds)\n",
    "lasso_coefs = lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "feature_names = X_train_enc.columns\n",
    "lasso_df = pd.DataFrame({'feature': feature_names, 'Coefficients': lasso_coefs})\n",
    "\n",
    "print(f'LASSO Train MSE: {np.around(lasso_train_mse,2)}')\n",
    "print(f'LASSO Test MSE: {np.around(lasso_test_mse,2)}')\n",
    "\n",
    "lasso_df.sort_values(by='Coefficients', ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Observation-LASSO</span>\n",
    "\n",
    "1. LASSO Train MSE: 69658578.85\n",
    "2. LASSO Test MSE: 75505613.41\n",
    "\n",
    "LASSO Regression gives us the same results as the previous 2 regression models with respect to the behvior of the best features with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFS - To identify a list of features that have the most influence on the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_lr_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                        ('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                        ('lr_model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_dict = {}\n",
    "sfs_lr_grid = ''\n",
    "sfs_lr_train_mse = ''\n",
    "sfs_lr_test_mse = ''\n",
    "\n",
    "param_dict = {'selector__n_features_to_select': [4, 5, 6]}\n",
    "sfs_lr_grid = GridSearchCV(sfs_lr_pipe, param_grid=param_dict).fit(X_train_enc, y_train)\n",
    "\n",
    "train_preds = sfs_lr_grid.predict(X_train_enc)\n",
    "test_preds = sfs_lr_grid.predict(X_test_enc)\n",
    "\n",
    "sfs_lr_train_mse = mean_squared_error(y_train, train_preds)\n",
    "sfs_lr_test_mse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Minimum Train MSE is : {np.around(sfs_lr_train_mse,2)}')\n",
    "print(f'Minimum Test MSE is: {np.around(sfs_lr_test_mse,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = ''\n",
    "best_selector = ''\n",
    "best_model = ''\n",
    "feature_names = ''\n",
    "coefs = ''\n",
    "\n",
    "best_estimator = sfs_lr_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = sfs_lr_grid.best_estimator_.named_steps['lr_model']\n",
    "feature_names = X_train_enc.columns[best_selector.get_support()]\n",
    "coefs = best_model.coef_\n",
    "\n",
    "print(best_estimator)\n",
    "print(f'Features from best selector: {feature_names}.')\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "pd.DataFrame([coefs.T], columns = feature_names, index = ['lr_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Degree & Linear Regression --- To identify the best degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "polyd_lr_train_mses = []\n",
    "polyd_lr_test_mses = []\n",
    "\n",
    "best_polyd = ''\n",
    "\n",
    "for i in range(1, 4):\n",
    "    pipe = Pipeline([('pfeat', PolynomialFeatures(degree = i, include_bias=False)),\n",
    "                     ('scale', StandardScaler()),\n",
    "                     ('linreg', LinearRegression())]).fit(X_train_enc, y_train)\n",
    "    \n",
    "    train_preds = pipe.predict(X_train_enc)\n",
    "    test_preds = pipe.predict(X_test_enc)\n",
    "    polyd_lr_train_mses.append(mean_squared_error(y_train, train_preds))\n",
    "    polyd_lr_test_mses.append(mean_squared_error(y_test, test_preds))\n",
    "    \n",
    "best_polyd_test = polyd_lr_test_mses.index(min(polyd_lr_test_mses)) + 1\n",
    "\n",
    "print(f'Best TEST performing degree model : {best_polyd_test}')\n",
    "print(f'Train MSE is: {np.around(polyd_lr_train_mses,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train MSE is: {np.around(polyd_lr_train_mses,2)}')\n",
    "print(f'Test MSE is: {np.around(polyd_lr_test_mses,2)}')\n",
    "best_polyd_train = polyd_lr_train_mses.index(min(polyd_lr_train_mses)) + 1\n",
    "best_polyd_test = polyd_lr_test_mses.index(min(polyd_lr_test_mses)) + 1\n",
    "\n",
    "print(f'Best TEST performing degree model : {best_polyd_test}')\n",
    "print(f'Best TRAIN performing degree model : {best_polyd_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial with Degree = 3 & Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pd_ridge_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 3, include_bias= False)),\n",
    "                          ('scaler', StandardScaler()), \n",
    "                          ('ridge', Ridge())])\n",
    "param_dict = {'ridge__alpha': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "pd_ridge_grid = ''\n",
    "pd_ridge_train_mse = ''\n",
    "pd_ridge_test_mse = ''\n",
    "pd_ridge_best_alpha = ''\n",
    "\n",
    "pd_ridge_grid = GridSearchCV(pd_ridge_pipe, param_grid=param_dict).fit(X_train_enc, y_train)\n",
    "\n",
    "train_preds = pd_ridge_grid.predict(X_train_enc)\n",
    "test_preds = pd_ridge_grid.predict(X_test_enc)\n",
    "\n",
    "pd_ridge_train_mse = mean_squared_error(y_train, train_preds)\n",
    "pd_ridge_test_mse = mean_squared_error(y_test, test_preds)\n",
    "pd_ridge_best_alpha = pd_ridge_grid.best_params_\n",
    "\n",
    "print(f'Polynomial with Degree =3 & Ridge Regression Train MSE: {np.around(pd_ridge_train_mse,2)}')\n",
    "print(f'Polynomial with Degree =3 & Ridge Regression Test MSE: {np.around(pd_ridge_test_mse,2)}')\n",
    "print(f'Best Alpha: {list(pd_ridge_best_alpha.values())[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression with  Degree = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lasso_pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 3, include_bias = False)),\n",
    "                          ('scaler', StandardScaler()),\n",
    "                          ('lasso', Lasso(random_state = 42))]).fit(X_train_enc, y_train)\n",
    "\n",
    "train_preds = pd_lasso_pipe.predict(X_train_enc)\n",
    "test_preds = pd_lasso_pipe.predict(X_test_enc)\n",
    "\n",
    "lasso_train_mse = mean_squared_error(y_train, train_preds)\n",
    "lasso_test_mse = mean_squared_error(y_test, test_preds)\n",
    "lasso_coefs = pd_lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "pd_lasso_coefs = pd_lasso_pipe.named_steps['lasso'].coef_\n",
    "feature_names = X_train_enc.columns\n",
    "\n",
    "print(f'LASSO Train MSE: {np.around(lasso_train_mse,2)}')\n",
    "print(f'LASSO Test MSE: {np.around(lasso_test_mse,2)}')\n",
    "\n",
    "list_lasso_coeff = list((zip(pd_lasso_pipe.named_steps['polyfeatures'].get_feature_names_out(), \n",
    "                             pd_lasso_pipe.named_steps['lasso'].coef_)))\n",
    "pd_lasso_df = pd.DataFrame(list_lasso_coeff, columns = [' Features', 'Lasso Coefficients'])\n",
    "pd_lasso_df.sort_values(by='Lasso Coefficients', ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd_lasso_pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "coefs = pd_lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "print(best_estimator)\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "errors = pd.DataFrame([coefs.T], columns = feature_names, index = ['lr_model'])\n",
    "errors[errors.columns[(abs(errors) > 0.000001).any()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "pipe = Pipeline([('pfeat', PolynomialFeatures(degree = 3, include_bias=False)),\n",
    "                     ('scale', StandardScaler()),\n",
    "                     ('linreg', LinearRegression())]).fit(X_train_enc, y_train)\n",
    "train_preds = pipe.predict(X_train_enc)\n",
    "test_preds = pipe.predict(X_test_enc)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.mean_squared_error(y_test, y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Feature Importance with best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(pipe, X_test_enc, y_test,\n",
    "                           random_state=123)\n",
    "pd.DataFrame({\"Variables\":X_test_enc.columns,\"Score\":r.importances_mean}).sort_values(by=\"Score\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLE CODE - DO NOT DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a heatmap to see which features have a strong corelation with price and use those variables to dig deeper\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "fig.suptitle('Correlation Analysis')\n",
    "ax = sns.heatmap(vehicles_df.corr(),cmap='RdYlGn', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
